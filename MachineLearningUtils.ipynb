{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ariahosseini/TradML/blob/main/MachineLearningUtils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rBYMsOYJ3rvm"
      },
      "outputs": [],
      "source": [
        "# libs\n",
        "import os, sys, warnings, itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy import sparse\n",
        "from scipy.stats import linregress\n",
        "# sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "# vis\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from IPython.core.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "wKHLHChD3rvo"
      },
      "outputs": [],
      "source": [
        "def summarize_columns(df):\n",
        "    num_rows = len(df)\n",
        "    summary = pd.DataFrame(df.dtypes, columns=[\"dtypes\"]).reset_index().rename(columns={\"index\": \"col_name\"})[[\"col_name\", \"dtypes\"]]\n",
        "    summary[\"missing\"] = df.isnull().sum().values\n",
        "    summary[\"missing_percent\"] = (summary[\"missing\"] * 100 / df.shape[0]).round(1)\n",
        "    summary[\"uniques\"] = df.nunique().values\n",
        "    summary[\"first_value\"] = df.iloc[0].values\n",
        "    summary[\"second_value\"] = df.iloc[1].values\n",
        "    summary[\"third_value\"] = df.iloc[2].values\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "t26S500j3rvo"
      },
      "outputs": [],
      "source": [
        "def reduce_memory_usage(df, category = False):\n",
        "    start_mem = df.memory_usage().sum() / (1024**2)\n",
        "    print(\"Memory usage of dataframe is {:2f} MB!\".format(start_mem))\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            if category:\n",
        "                df[col] = df[col].astype(\"category\")\n",
        "    end_mem = df.memory_usage().sum() / (1024**2)\n",
        "    print(\"Memory usage after optimization is {:2f} MB!\".format(end_mem))\n",
        "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem-end_mem) / start_mem))"
      ]
    },
    {
      "source": [
        "def display_df(df, message = \" \"):\n",
        "    print(\"Dataframe: {}\".format(message))\n",
        "    num_rows, num_cols = df.shape\n",
        "    print(f\"num_rows = {num_rows:,} \\nnum_cols = {num_cols:,}\")\n",
        "    display(df.head())\n",
        "    print(\"Info:\")\n",
        "    df.info()\n",
        "    if df.isnull().any().any():\n",
        "        print(\"Number of null data points:\")\n",
        "        print(df.isnull().sum()[df.isnull().sum() != 0])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Phpa4E1P6hBj"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "source": [
        "def plot_variables(df, vars_to_plot, cts_vars, num_cols=2, hist_num_bins=20):\n",
        "    num_rows = (len(vars_to_plot) + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, var in enumerate(vars_to_plot):\n",
        "        ax = axes[i]\n",
        "        if var in cts_vars:\n",
        "            ax.hist(df[var], bins=hist_num_bins)\n",
        "            plt.xticks(rotation=45)\n",
        "            ax.set_title(f\"{var} Histogram\")\n",
        "        else:\n",
        "            df[var].value_counts().plot(kind=\"bar\", ax=ax, title=f\"{var} Counts\")\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nfJxwuD67EiD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_plot_vars(df, vars_to_plot, num_cols=2):\n",
        "    num_rows = (len(vars_to_plot) + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, var in enumerate(vars_to_plot):\n",
        "        ax = axes[i]\n",
        "        sns.scatterplot(x=var, y='index', data=df.reset_index(), ax=ax)\n",
        "        ax.set_title(f'Distribution of {var}')\n",
        "        ax.set_xlabel(var)\n",
        "        ax.set_ylabel('Index')\n",
        "        ax.tick_params(axis='x', labelrotation=45)\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0tE6NeNF0dJb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "source": [
        "def plot_regs(df, cts_vars, response, num_cols=3, dot_size=10, line_width=3):\n",
        "    num_rows = (len(cts_vars) + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, var in enumerate(cts_vars):\n",
        "        ax = axes[i]\n",
        "        slope, intercept, r_value, p_value, std_error = linregress(df[var], df[response])\n",
        "        sns.regplot(x=df[var], y=df[response], ax=ax,\n",
        "                   scatter_kws={\"s\": dot_size},\n",
        "                   line_kws={\"linewidth\": line_width},\n",
        "                   label=\"y={0:.1f}x+{1:.1f}\".format(slope, intercept)).legend(loc=\"best\")\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    fig.suptitle(\"Regression Scatter Plots for {}\".format(response), fontsize=16)\n",
        "    fig.subplots_adjust(top=0.95)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gM27PpSS8Lwi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_clfs(df, feature_vars, response, num_cols=3, dot_size=10):\n",
        "    num_rows = (len(feature_vars) + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 5))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, var in tqdm(enumerate(feature_vars), total=len(feature_vars), desc=\"Processing features\"):\n",
        "        ax = axes[i]\n",
        "\n",
        "        X = df[[var]]\n",
        "        y = df[response]\n",
        "\n",
        "        if df[var].dtype == 'object' or df[var].dtype == 'category' or len(df[var].unique()) < 10:\n",
        "            preprocessor = ColumnTransformer(\n",
        "                transformers=[('cat', Pipeline(steps=[\n",
        "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                    ('onehot', OneHotEncoder(drop='first'))\n",
        "                ]), [0])],\n",
        "                remainder='passthrough'\n",
        "            )\n",
        "        else:\n",
        "            preprocessor = ColumnTransformer(\n",
        "                transformers=[('num', Pipeline(steps=[\n",
        "                    ('imputer', SimpleImputer(strategy='mean')),\n",
        "                    ('scaler', StandardScaler())\n",
        "                ]), [0])],\n",
        "                remainder='passthrough'\n",
        "            )\n",
        "\n",
        "        pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                   ('classifier', LogisticRegression())])\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "        pipeline.fit(X_train, y_train)\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        if len(np.unique(y_test)) == 2:\n",
        "          auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n",
        "        else:\n",
        "          auc = roc_auc_score(y_test, pipeline.predict_proba(X_test), multi_class='ovr', average='macro')\n",
        "\n",
        "        if df[var].dtype == 'object' or df[var].dtype == 'category' or len(df[var].unique()) < 10:\n",
        "            sns.countplot(x=X_train[var], hue=y_train, ax=ax, palette='coolwarm')\n",
        "        else:\n",
        "            sns.scatterplot(x=X_train[var], y=y_train, hue=y_train, ax=ax, s=dot_size, palette='coolwarm')\n",
        "\n",
        "            x_vals = np.linspace(X_train[var].min(), X_train[var].max(), 100).reshape(-1, 1)\n",
        "            y_vals = pipeline.predict_proba(x_vals)[:, 1]\n",
        "            ax.plot(x_vals, y_vals, color='black', linewidth=2, label=f'Acc: {accuracy:.2f}, AUC: {auc:.2f}')\n",
        "\n",
        "        ax.set_title(f\"Logistic Regression for {var}\")\n",
        "        ax.legend(loc='best')\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "\n",
        "    fig.suptitle(f\"Logistic Regression with Each Feature Separately ({response})\", fontsize=16)\n",
        "    fig.subplots_adjust(top=0.95)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hcX_Vdh8Nz33"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "source": [
        "@staticmethod\n",
        "def display_side_by_side(dfs: list, captions: list, table_spacing=5):\n",
        "    if len(dfs) != len(captions):\n",
        "        raise ValueError(\"The number of DataFrames and captions must be equal!\")\n",
        "\n",
        "    output = \"\"\n",
        "    for (caption, df) in zip(captions, dfs):\n",
        "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
        "        output += table_spacing * \"\\xa0\"\n",
        "    display(HTML(output))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "eJOzsktU8o1t"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "source": [
        "def one_hot_encode(df, ohe, var_list, drop_original=True, sparse_matrix=False, handle_unknown='ignore'):\n",
        "    if not sparse_matrix:\n",
        "        temp_df = pd.DataFrame(data=ohe.transform(df[var_list]), columns=ohe.get_feature_names_out())\n",
        "    else:\n",
        "        temp_df = sparse.csr_matrix(ohe.transform(df[var_list]))\n",
        "\n",
        "    df = pd.concat([df.reset_index(drop=True), temp_df], axis=1)\n",
        "    if drop_original:\n",
        "        df.drop(columns=var_list, axis=1, inplace=True)\n",
        "    return df"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "SrA2ik_a9HAP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_conf_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0eedud9TQW2E"
      },
      "execution_count": 56,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyML",
      "language": "python",
      "name": "pyml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}